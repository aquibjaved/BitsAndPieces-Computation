{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyO5STpTEgvkgFN1AvX/MPJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquibjaved/Bits_and_Pieces_DL/blob/main/Basics_of_lora3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cccntu/minLoRA.git\n",
        "!cd minLoRA\n",
        "!pip install -e /content/minLoRA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ubGq9s-d5Am",
        "outputId": "41b88d3e-ee54-408c-97c7-822bffdb121d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'minLoRA'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 42 (delta 21), reused 36 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (42/42), 15.04 KiB | 2.15 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "Obtaining file:///content/minLoRA\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from minLoRA==0.1.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->minLoRA==0.1.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->minLoRA==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->minLoRA==0.1.0) (1.3.0)\n",
            "Installing collected packages: minLoRA\n",
            "  Running setup.py develop for minLoRA\n",
            "Successfully installed minLoRA-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XHgXd4TYdxQW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.parametrize as P\n",
        "from sklearn.datasets import load_iris\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from minlora import add_lora, apply_to_lora, disable_lora, enable_lora, get_lora_params, merge_lora, name_is_lora, remove_lora, load_multiple_lora, select_lora, get_lora_state_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-fkB4OLogPPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = FashionNet(input_dims=784, num_class=10, input_hidden_size=1000, hidden_layer_size=2000)\n",
        "# Step 1: Add LoRA to the model\n",
        "# add_lora(model)\n",
        "\n",
        "# Step 2: Collect the parameters, pass them to the optimizer\n",
        "\n",
        "# parameters = [\n",
        "#     {\"params\": list(get_lora_params(model))},\n",
        "# ]\n",
        "# optimizer = torch.optim.AdamW(parameters, lr=1e-3)\n",
        "\n",
        "# Step 3: Train the model\n",
        "# ...\n",
        "\n",
        "# Step 4: export the LoRA parameters\n",
        "# lora_state_dict = get_lora_state_dict(model)"
      ],
      "metadata": {
        "id": "mb85CLDbfvXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtFb2xuVgH0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform to normalize the data and flatten each image into a 1D array\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    data, target = zip(*batch)\n",
        "    data = torch.stack(data)\n",
        "    target = torch.tensor(target)\n",
        "    return data.cuda(), target.cuda()\n",
        "\n",
        "train_dataset = datasets.FashionMNIST('~/.data', download=True, train=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST('~/.data', download=True, train=False, transform=transform)\n",
        "def split_dataset(dataset, labels):\n",
        "    indices = [i for i, (data, label) in enumerate(dataset) if label in labels]\n",
        "    return torch.utils.data.Subset(dataset, indices)\n",
        "\n",
        "labels_1 = [0, 1, 2, 3, 4]\n",
        "labels_2 = [5, 6, 7, 8, 9]\n",
        "\n",
        "train_dataset_04 = split_dataset(train_dataset, labels_1)\n",
        "train_dataset_59 = split_dataset(train_dataset, labels_2)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader_1 = torch.utils.data.DataLoader(train_dataset_04, batch_size=batch_size, shuffle=True)\n",
        "train_loader_2 = torch.utils.data.DataLoader(train_dataset_59, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "GzlKXpsXgK3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f742873d-0ae0-4a19-ca37-d31283e507ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 116904893.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 11135637.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 63605356.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 25492652.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def train_model(epochs:int, train_loader, model, optimizer, criterion):\n",
        "  model.train()\n",
        "  train_loss_per_epoch = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss_train = 0.0\n",
        "\n",
        "    for data_batch, target_batch in train_loader:\n",
        "\n",
        "        data_batch = data_batch.to('cuda')\n",
        "        target_batch = target_batch.to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data_batch)\n",
        "        loss_train = criterion(output, target_batch)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_train += loss_train.item()\n",
        "\n",
        "    epcoh_loss_train = running_loss_train / len(train_loader)\n",
        "\n",
        "    train_loss_per_epoch.append(epcoh_loss_train)\n",
        "\n",
        "\n",
        "    if epoch %2 == 0:\n",
        "      print(f'Epoch {epoch} Train loss {epcoh_loss_train}')\n",
        "  return train_loss_per_epoch\n",
        "\n",
        "device='cuda'\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def test(test_loader, net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    wrong_counts = [0 for i in range(10)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = net(x)\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct +=1\n",
        "                else:\n",
        "                    wrong_counts[y[idx]] +=1\n",
        "                total +=1\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')\n",
        "    for i in range(len(wrong_counts)):\n",
        "        print(f'wrong counts for the Label {i}: {wrong_counts[i]}')\n",
        "\n"
      ],
      "metadata": {
        "id": "BimpfRyoOFyp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNet(nn.Module):\n",
        "  def __init__(self, input_dims, num_class, input_hidden_size: 1000, hidden_layer_size:2000):\n",
        "\n",
        "    super().__init__()\n",
        "    self.input_dims = input_dims\n",
        "    self.num_class = num_class\n",
        "\n",
        "    self.input_layer = nn.Linear(in_features=self.input_dims, out_features=1000)\n",
        "    self.hidden_layer = nn.Linear(in_features=1000, out_features=2000)\n",
        "    self.output_layer = nn.Linear(in_features=2000, out_features=self.num_class)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.input_layer(x))\n",
        "    out = F.relu(self.hidden_layer(out))\n",
        "    out = self.output_layer(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "1KHtm1oKPLEG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "# Define the class names for Fashion MNIST\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "BigNet = FashionNet(input_dims=784, num_class=len(class_names), input_hidden_size=1000, hidden_layer_size=2000)\n",
        "optimizer = optim.SGD(BigNet.parameters(), lr=0.0001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Assume `model` is your model\n",
        "if cuda_available:\n",
        "    BigNet = BigNet.to('cuda')\n",
        "    optimizer = optim.SGD(BigNet.parameters(), lr=0.011, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss().to('cuda')\n",
        "\n",
        "is_on_gpu = next(BigNet.parameters()).is_cuda\n",
        "print(f'Model is on GPU: {is_on_gpu}')\n",
        "\n",
        "trainable_params = sum(p.numel() for p in BigNet.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable (tunable) parameters: {trainable_params}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvZrP8UEOLvv",
        "outputId": "b30b21a1-3706-4b3f-8b8d-4b191fade219"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on GPU: True\n",
            "Number of trainable (tunable) parameters: 2807010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoss = train_model(epochs=10,\n",
        "                        train_loader=train_loader_1,\n",
        "                        optimizer = optimizer,\n",
        "                        criterion=criterion,\n",
        "                        model=BigNet,\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JynKQFR4OouK",
        "outputId": "3972a1dd-c247-4ad2-f191-f59a7be9820b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Train loss 0.4198003794783468\n",
            "Epoch 2 Train loss 0.264796864948293\n",
            "Epoch 4 Train loss 0.2255258931756528\n",
            "Epoch 6 Train loss 0.1997014654280026\n",
            "Epoch 8 Train loss 0.17623552429015193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(\n",
        "      test_loader=test_loader,\n",
        "      net=BigNet,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH8pLhKnPhuO",
        "outputId": "c35b964e-bb6f-4d22-acfa-795266ea1999"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.454\n",
            "wrong counts for the Label 0: 71\n",
            "wrong counts for the Label 1: 37\n",
            "wrong counts for the Label 2: 117\n",
            "wrong counts for the Label 3: 64\n",
            "wrong counts for the Label 4: 172\n",
            "wrong counts for the Label 5: 1000\n",
            "wrong counts for the Label 6: 1000\n",
            "wrong counts for the Label 7: 1000\n",
            "wrong counts for the Label 8: 1000\n",
            "wrong counts for the Label 9: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model = BigNet.to('cpu')\n",
        "# Step 1: Add LoRA to the model\n",
        "add_lora(lora_model)\n",
        "\n",
        "# Step 2: Collect the parameters, pass them to the optimizer\n",
        "\n",
        "parameters = [\n",
        "    {\"params\": list(get_lora_params(lora_model))},\n",
        "]\n",
        "optimizer = optim.SGD(BigNet.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "# Step 3: Train the model\n",
        "# ...\n",
        "\n",
        "# Step 4: export the LoRA parameters\n",
        "# lora_state_dict = get_lora_state_dict(model)\n"
      ],
      "metadata": {
        "id": "h-V8qWwfOsK4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx-nd_HtYKPx",
        "outputId": "1dec6962-bb72-4284-e8d6-540f1d5fc360"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionNet(\n",
              "  (input_layer): ParametrizedLinear(\n",
              "    in_features=784, out_features=1000, bias=True\n",
              "    (parametrizations): ModuleDict(\n",
              "      (weight): ParametrizationList(\n",
              "        (0): LoRAParametrization()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (hidden_layer): ParametrizedLinear(\n",
              "    in_features=1000, out_features=2000, bias=True\n",
              "    (parametrizations): ModuleDict(\n",
              "      (weight): ParametrizationList(\n",
              "        (0): LoRAParametrization()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (output_layer): ParametrizedLinear(\n",
              "    in_features=2000, out_features=10, bias=True\n",
              "    (parametrizations): ModuleDict(\n",
              "      (weight): ParametrizationList(\n",
              "        (0): LoRAParametrization()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoss = train_model(epochs=10,\n",
        "                        train_loader=train_loader_2,\n",
        "                        optimizer = optimizer,\n",
        "                        criterion=criterion,\n",
        "                        model=lora_model,\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJvvCj5BYZSC",
        "outputId": "993f4df5-d3d3-4d3f-fc88-692c3cbacfc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Train loss 3.0382540015015267\n",
            "Epoch 2 Train loss 0.8434577175040743\n",
            "Epoch 4 Train loss 0.46272345780055407\n",
            "Epoch 6 Train loss 0.37157765259620734\n",
            "Epoch 8 Train loss 0.32912180024677756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function\n",
        "test(\n",
        "      test_loader=test_loader,\n",
        "      net=lora_model,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKhYCl1oYjBJ",
        "outputId": "b096151c-8cd3-4da9-bd96-bcfe873bc203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.517\n",
            "wrong counts for the Label 0: 1000\n",
            "wrong counts for the Label 1: 279\n",
            "wrong counts for the Label 2: 998\n",
            "wrong counts for the Label 3: 1000\n",
            "wrong counts for the Label 4: 1000\n",
            "wrong counts for the Label 5: 181\n",
            "wrong counts for the Label 6: 51\n",
            "wrong counts for the Label 7: 133\n",
            "wrong counts for the Label 8: 88\n",
            "wrong counts for the Label 9: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_state_dict = get_lora_state_dict(lora_model)\n",
        "\n",
        "original_model = BigNet.to('cpu')\n",
        "add_lora(lora_model)\n",
        "_ = original_model.load_state_dict(lora_state_dict, strict=False) # original model with lora trained weights\n"
      ],
      "metadata": {
        "id": "ES_hClT_Y2_3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_lora(original_model)\n"
      ],
      "metadata": {
        "id": "Bn032spCZoWI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0xBcdc0ZyYs",
        "outputId": "e35fb2b8-11d7-4dd3-fb71-d4124b754d7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionNet(\n",
              "  (input_layer): Linear(in_features=784, out_features=1000, bias=True)\n",
              "  (hidden_layer): Linear(in_features=1000, out_features=2000, bias=True)\n",
              "  (output_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function\n",
        "test(\n",
        "      test_loader=test_loader,\n",
        "      net=original_model.to('cuda'),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx5fzaXhZs84",
        "outputId": "9f393951-05d0-4bfa-90fe-b56cecb39134"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.518\n",
            "wrong counts for the Label 0: 1000\n",
            "wrong counts for the Label 1: 280\n",
            "wrong counts for the Label 2: 998\n",
            "wrong counts for the Label 3: 1000\n",
            "wrong counts for the Label 4: 1000\n",
            "wrong counts for the Label 5: 155\n",
            "wrong counts for the Label 6: 47\n",
            "wrong counts for the Label 7: 160\n",
            "wrong counts for the Label 8: 89\n",
            "wrong counts for the Label 9: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrCW1rNGZ1ra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}